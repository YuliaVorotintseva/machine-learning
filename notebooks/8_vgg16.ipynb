{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"/kaggle/input/dogs-vs-cats/test1.zip\n/kaggle/input/dogs-vs-cats/train.zip\n/kaggle/input/dogs-vs-cats/sampleSubmission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import keras\nfrom keras.preprocessing import image\nfrom keras.applications.imagenet_utils import preprocess_input\n\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, InputLayer, Flatten\nfrom keras.models import Model, Sequential\n\nimport random","metadata":{"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!unzip -q ../input/dogs-vs-cats/train.zip","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"os.mkdir('train/cat')\nos.mkdir('train/dog')","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"max_imgs = 1000\ncats = 0\ndogs = 0\n\nfor file in os.walk('train'):\n    filenames = file[2]\n    for filename in filenames:\n        if filename.find('cat') != -1:\n            if cats < max_imgs:\n                os.replace('train/' + filename, 'train/cat/' + filename[4:])\n                cats += 1\n        elif filename.find('dog') != -1:\n            if dogs < max_imgs:\n                os.replace('train/' + filename, 'train/dog/' + filename[4:])\n                dogs += 1","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"categories = [x[0] for x in os.walk('train') if x[0]][1:]","metadata":{"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"['train/dog', 'train/cat']"},"metadata":{}}]},{"cell_type":"code","source":"# helper function to load image and return it and input vector\ndef get_image(path):\n    img = image.load_img(path, target_size=(224, 224))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = preprocess_input(x)\n    return img, x","metadata":{"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"data = []\nfor c, category in enumerate(categories):\n    images = [os.path.join(dp, f) for dp, dn, filenames \n              in os.walk(category) for f in filenames \n              if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]\n    for img_path in images:\n        img, x = get_image(img_path)\n        data.append({'x':np.array(x[0]), 'y':c})\n\n# count the number of classes\nnum_classes = len(categories)","metadata":{"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"random.shuffle(data)\ntrain_split = 0.8\nidx_test = int((train_split) * len(data))\n\ndata_train = data[:idx_test]\ndata_test = data[idx_test:]","metadata":{"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"x_train, y_train = np.array([t[\"x\"] for t in data_train]), [t[\"y\"] for t in data_train]\nx_test, y_test = np.array([t[\"x\"] for t in data_test]), [t[\"y\"] for t in data_test]","metadata":{"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"x_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\n# convert labels to one-hot vectors\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)","metadata":{"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def create_model(\n    filters=[20, 20],\n    pool_size=[(10, 10), (10, 10)],\n    dense_size=[400, 400]):\n    \n    model = Sequential()\n\n    model.add(InputLayer(input_shape=x_train.shape[1:]))\n    model.add(Conv2D(filters[0], kernel_size=3))\n    model.add(Conv2D(filters[1], kernel_size=3))\n    model.add(MaxPooling2D(pool_size=pool_size[0]))\n    model.add(Conv2D(filters[0], kernel_size=3))\n    model.add(Conv2D(filters[1], kernel_size=3))\n    model.add(MaxPooling2D(pool_size=pool_size[0]))\n    model.add(Flatten())\n    model.add(Dense(400, activation='relu'))\n    model.add(Dense(400, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    return model","metadata":{"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"model = create_model()\nmodel.summary()","metadata":{"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_2 (Conv2D)            (None, 222, 222, 20)      560       \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 220, 220, 20)      3620      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 22, 22, 20)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 20, 20, 20)        3620      \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 18, 18, 20)        3620      \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 1, 1, 20)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 20)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 400)               8400      \n_________________________________________________________________\ndense_4 (Dense)              (None, 400)               160400    \n_________________________________________________________________\ndense_5 (Dense)              (None, 2)                 802       \n=================================================================\nTotal params: 181,022\nTrainable params: 181,022\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(x_train, y_train, batch_size=10, epochs=10)","metadata":{"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch 1/10\n160/160 [==============================] - 74s 458ms/step - loss: 0.7366 - accuracy: 0.5604\nEpoch 2/10\n160/160 [==============================] - 71s 444ms/step - loss: 0.5997 - accuracy: 0.6741\nEpoch 3/10\n160/160 [==============================] - 71s 443ms/step - loss: 0.5111 - accuracy: 0.7574\nEpoch 4/10\n160/160 [==============================] - 70s 439ms/step - loss: 0.4043 - accuracy: 0.8219\nEpoch 5/10\n160/160 [==============================] - 72s 452ms/step - loss: 0.2713 - accuracy: 0.8955\nEpoch 6/10\n160/160 [==============================] - 83s 521ms/step - loss: 0.2189 - accuracy: 0.9121\nEpoch 7/10\n160/160 [==============================] - 74s 464ms/step - loss: 0.0838 - accuracy: 0.9763\nEpoch 8/10\n160/160 [==============================] - 74s 460ms/step - loss: 0.0299 - accuracy: 0.9912\nEpoch 9/10\n160/160 [==============================] - 73s 456ms/step - loss: 0.1099 - accuracy: 0.9554\nEpoch 10/10\n160/160 [==============================] - 71s 445ms/step - loss: 0.0804 - accuracy: 0.9785\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f40a64bfb50>"},"metadata":{}}]},{"cell_type":"code","source":"loss, accuracy = model.evaluate(x_test, y_test, verbose=0)","metadata":{"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Метрики качества на тестовой выборке\nprint('LOSS', loss)\nprint('ACCURACY', accuracy)","metadata":{"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"LOSS 1.4530487060546875\nACCURACY 0.7074999809265137\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Точночть 71%","metadata":{}},{"cell_type":"markdown","source":"# VGG16","metadata":{}},{"cell_type":"code","source":"vgg = keras.applications.VGG16(weights='imagenet', include_top=True)\nvgg.summary()","metadata":{"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n553467904/553467096 [==============================] - 7s 0us/step\nModel: \"vgg16\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 25088)             0         \n_________________________________________________________________\nfc1 (Dense)                  (None, 4096)              102764544 \n_________________________________________________________________\nfc2 (Dense)                  (None, 4096)              16781312  \n_________________________________________________________________\npredictions (Dense)          (None, 1000)              4097000   \n=================================================================\nTotal params: 138,357,544\nTrainable params: 138,357,544\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# make a reference to VGG's input layer\ninp = vgg.input\n\n# make a new softmax layer with num_classes neurons\nnew_classification_layer = Dense(num_classes, activation='softmax')\n\n# connect our new layer to the second to last layer in VGG, and make a reference to it\nout = new_classification_layer(vgg.layers[-2].output)\n\n# create a new network between inp and out\nmodel_new = Model(inp, out)\n\nmodel_new.summary()","metadata":{"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 25088)             0         \n_________________________________________________________________\nfc1 (Dense)                  (None, 4096)              102764544 \n_________________________________________________________________\nfc2 (Dense)                  (None, 4096)              16781312  \n_________________________________________________________________\ndense_6 (Dense)              (None, 2)                 8194      \n=================================================================\nTotal params: 134,268,738\nTrainable params: 134,268,738\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"for l, layer in enumerate(model_new.layers[:-1]):\n    layer.trainable = False\n\n# ensure the last layer is trainable/not frozen\nfor l, layer in enumerate(model_new.layers[-1:]):\n    layer.trainable = True","metadata":{"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model_new.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nmodel_new.summary()","metadata":{"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 25088)             0         \n_________________________________________________________________\nfc1 (Dense)                  (None, 4096)              102764544 \n_________________________________________________________________\nfc2 (Dense)                  (None, 4096)              16781312  \n_________________________________________________________________\ndense_6 (Dense)              (None, 2)                 8194      \n=================================================================\nTotal params: 134,268,738\nTrainable params: 8,194\nNon-trainable params: 134,260,544\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model_new.fit(x_train, y_train, batch_size=10, epochs=10)","metadata":{"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Epoch 1/10\n160/160 [==============================] - 304s 2s/step - loss: 0.5062 - accuracy: 0.7464\nEpoch 2/10\n160/160 [==============================] - 305s 2s/step - loss: 0.3404 - accuracy: 0.8382\nEpoch 3/10\n160/160 [==============================] - 307s 2s/step - loss: 0.3207 - accuracy: 0.8529\nEpoch 4/10\n160/160 [==============================] - 303s 2s/step - loss: 0.2798 - accuracy: 0.8804\nEpoch 5/10\n160/160 [==============================] - 301s 2s/step - loss: 0.2274 - accuracy: 0.9016\nEpoch 6/10\n160/160 [==============================] - 303s 2s/step - loss: 0.2841 - accuracy: 0.8686\nEpoch 7/10\n160/160 [==============================] - 302s 2s/step - loss: 0.2330 - accuracy: 0.8949\nEpoch 8/10\n160/160 [==============================] - 314s 2s/step - loss: 0.1968 - accuracy: 0.9162\nEpoch 9/10\n160/160 [==============================] - 301s 2s/step - loss: 0.2628 - accuracy: 0.8850\nEpoch 10/10\n160/160 [==============================] - 303s 2s/step - loss: 0.2086 - accuracy: 0.9015\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f407da03050>"},"metadata":{}}]},{"cell_type":"code","source":"loss, accuracy = model_new.evaluate(x_test, y_test, verbose=0)","metadata":{"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Метрики качества на тестовой выборке\nprint('LOSS', loss)\nprint('ACCURACY', accuracy)","metadata":{"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"LOSS 0.2906246483325958\nACCURACY 0.8849999904632568\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Точночть 88.5%","metadata":{}},{"cell_type":"markdown","source":"# Вывод","metadata":{}},{"cell_type":"markdown","source":"В результате выполнения данной работы был реализован классификатор, показывающий точность 71%, также был использован VGG16 классификатор, показывающий лучшую в сравнении с собственной реализацией точность - 88.5%.","metadata":{}}]}