{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_df = pd.read_csv('data/titanic_train.csv')\n",
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Age          891 non-null    float64\n",
      " 5   SibSp        891 non-null    int64  \n",
      " 6   Parch        891 non-null    int64  \n",
      " 7   Ticket       891 non-null    object \n",
      " 8   Fare         891 non-null    float64\n",
      " 9   Bsex         891 non-null    int64  \n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 69.7+ KB\n"
     ]
    }
   ],
   "source": [
    "live = { \n",
    "    0: 'Perished',\n",
    "    1: 'Survived'\n",
    "}\n",
    "\n",
    "sex = {\n",
    "    'male': 0,\n",
    "    'female': 1\n",
    "}\n",
    "\n",
    "titanic_df['Bsex'] = titanic_df['Sex'].apply(lambda x: sex[x])\n",
    "features = titanic_df[['Pclass', 'Bsex']].to_numpy()\n",
    "labels = titanic_df['Survived'].to_numpy()\n",
    "\n",
    "titanic_df = titanic_df.fillna(titanic_df.mean()).drop(['Sex', 'Cabin', 'Embarked'], axis = 1)\n",
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции активации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer(p = 4, activation = 'ReLU'):\n",
    "    return (p, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_act(x, der = False):\n",
    "    # Производная\n",
    "    if (der == True):\n",
    "        f = 1 / (1 + np.exp(-x)) * (1 - 1 / (1 + np.exp(-x)))\n",
    "    else:\n",
    "        f = 1 / (1 + np.exp(-x))\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rectifier Linear Unit\n",
    "def ReLU_act(x, der = False):\n",
    "    if (der == True):\n",
    "        f = np.heaviside(x, 1)\n",
    "    else:\n",
    "        f = np.maximum(x, 0)\n",
    "    return f\n",
    "    \n",
    "def list_act():\n",
    "    return ['sigmoid', 'ReLU'] \n",
    "    \n",
    "def get_act(string = 'ReLU'):\n",
    "    if string == 'ReLU':\n",
    "        return ReLU_act\n",
    "    elif string == 'sigmoid':\n",
    "        return sigmoid_act\n",
    "    else :\n",
    "        return sigmoid_act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Класс нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    np.random.seed(10)\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.HiddenLayer = []\n",
    "        self.w = []\n",
    "        self.b = []\n",
    "        self.phi = []\n",
    "        self.mu = []\n",
    "        self.eta = 1\n",
    "    \n",
    "    \n",
    "    # Метод добавления слоя\n",
    "    def add(self, lay = (4, 'ReLU')):\n",
    "        self.HiddenLayer.append(lay)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def FeedForward(w, b, phi, x):\n",
    "        return phi(np.dot(w, x) + b)\n",
    "    \n",
    "    \n",
    "    # Градиентный спуск\n",
    "    def BackPropagation(self, x, z, Y, w, b, phi):\n",
    "        self.delta = []\n",
    "        self.W = []\n",
    "        self.B = []\n",
    "        \n",
    "        # Вычисление последней ошибкт \n",
    "        self.delta.append((z[len(z) - 1] - Y) * phi[len(z) - 1](z[len(z) - 1], der = True))\n",
    "        for i in range(0, len(z) - 1):\n",
    "            self.delta.append(np.dot(self.delta[i], w[len(z) - 1 - i] ) * phi[len(z) - 2 - i](z[len(z) - 2 - i], der = True) )\n",
    "        \n",
    "        # Сортировка массива ошибок от первой к последней\n",
    "        self.delta = np.flip(self.delta, 0)  \n",
    "        \n",
    "        # Определение дельты как ошибкы, деленной на количество обучающих выборок\n",
    "        self.delta = self.delta/self.X.shape[0] \n",
    "        \n",
    "        # С первого слоя\n",
    "        self.W.append( w[0] - self.eta * np.kron(self.delta[0], x).reshape( len(z[0]), x.shape[0] ) )\n",
    "        self.B.append( b[0] - self.eta * self.delta[0] )\n",
    "        \n",
    "        for i in range(1, len(z)):\n",
    "            self.W.append( w[i] - self.eta * np.kron(self.delta[i], z[i-1]).reshape(len(z[i]), len(z[i-1])) )\n",
    "            self.B.append( b[i] - self.eta * self.delta[i] )\n",
    "            \n",
    "        # Возврат параметров w, b по убыванию\n",
    "        return np.array(self.W), np.array(self.B)\n",
    "    \n",
    "    \n",
    "    def Fit(self, X_train, Y_train):       \n",
    "        self.X = X_train\n",
    "        self.Y = Y_train\n",
    "        \n",
    "        for i in range(0, len(self.HiddenLayer)):\n",
    "            if i == 0:\n",
    "                self.w.append( np.random.randn(self.HiddenLayer[i][0] , self.X.shape[1])/np.sqrt(2/self.X.shape[1]) )\n",
    "                self.b.append( np.random.randn(self.HiddenLayer[i][0])/np.sqrt(2/self.X.shape[1]))\n",
    "                \n",
    "                for act in list_act():\n",
    "                    if self.HiddenLayer[i][1] == act :\n",
    "                        self.phi.append(get_act(act))\n",
    "            else:\n",
    "                self.w.append( np.random.randn(self.HiddenLayer[i][0] , self.HiddenLayer[i-1][0] ) / np.sqrt(2 / self.HiddenLayer[i - 1][0]))\n",
    "                self.b.append( np.random.randn(self.HiddenLayer[i][0]) / np.sqrt(2 / self.HiddenLayer[i - 1][0]))\n",
    "\n",
    "                for act in list_act():\n",
    "                    if self.HiddenLayer[i][1] == act :\n",
    "                        self.phi.append(get_act(act))\n",
    "          \n",
    "        # Цикл по обучающей выборке\n",
    "        for I in range(0, self.X.shape[0]): \n",
    "            self.z = []\n",
    "            self.z.append(self.FeedForward(self.w[0], self.b[0], self.phi[0], self.X[I]))\n",
    "            \n",
    "            for i in range(1, len(self.HiddenLayer)):\n",
    "                self.z.append(self.FeedForward(self.w[i] , self.b[i], self.phi[i], self.z[i - 1]))\n",
    "                  \n",
    "            self.w, self.b  = self.BackPropagation(self.X[I], self.z, self.Y[I], self.w, self.b, self.phi)\n",
    "            self.mu.append((1/2) * np.dot(self.z[len(self.z) - 1] - self.Y[I], self.z[len(self.z) - 1] - self.Y[I]))\n",
    "            \n",
    "            \n",
    "    def predict(self, X_test):\n",
    "        self.pred = []\n",
    "        self.XX = X_test\n",
    "        \n",
    "        # Цикл по обучающей выборке\n",
    "        for I in range(0, self.XX.shape[0]):\n",
    "            self.z = []\n",
    "            self.z.append(self.FeedForward(self.w[0] , self.b[0], self.phi[0], self.XX[I]))\n",
    "            \n",
    "            for i in range(1, len(self.HiddenLayer)):\n",
    "                self.z.append( self.FeedForward(self.w[i] , self.b[i], self.phi[i], self.z[i-1]))\n",
    "       \n",
    "            # Теперь необходим бинарный классификатор, порог 0,5\n",
    "            # if y < 0.5 the output is zero, otherwise is zero\n",
    "            self.pred.append(np.heaviside(self.z[-1] - 0.5, 1)[0])\n",
    "        return np.array(self.pred)\n",
    "    \n",
    "    \n",
    "    def get_accuracy(self):\n",
    "        return np.array(self.mu)\n",
    "    \n",
    "    \n",
    "    def get_avg_accuracy(self):\n",
    "        self.batch_loss = []\n",
    "        \n",
    "        for i in range(0, 10):\n",
    "            self.loss_avg = 0\n",
    "            \n",
    "            for m in range(0, (int(math.ceil((self.X.shape[0]-10) / 10.0))   ) - 1):\n",
    "                #self.loss_avg += self.mu[60*i+m]/60\n",
    "                self.loss_avg += self.mu[(int(math.ceil((self.X.shape[0]-10) / 10.0)) )*i + m] / (int(math.ceil((self.X.shape[0]-10) / 10.0)) )\n",
    "            \n",
    "            self.batch_loss.append(self.loss_avg)\n",
    "        return np.array(self.batch_loss)\n",
    "    \n",
    "    \n",
    "    def set_learning_rate(self, et=1):\n",
    "        self.eta = et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_model = NN()\n",
    "\n",
    "titanic_model.add(get_layer(8, 'ReLU'))\n",
    "titanic_model.add(get_layer(4, 'ReLU'))\n",
    "titanic_model.add(get_layer(1, 'sigmoid'))\n",
    "\n",
    "titanic_model.set_learning_rate(0.8)\n",
    "titanic_model.Fit(X_train, Y_train)\n",
    "\n",
    "acc_val = titanic_model.get_accuracy()\n",
    "acc_avg_val = titanic_model.get_avg_accuracy()\n",
    "\n",
    "predictions = titanic_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
